---
title: "BIDA302: Lesson 2"
subtitle: "Variable types"
output: learnr::tutorial
runtime: shiny_prerendered
---



<!-- This file by Martin Monkman is licensed under a Creative Commons Attribution 4.0 International License. -->


```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

# packages used in the tutorial
library(tidyverse)
library(gapminder)
library(readxl)

```


## 1. Variable types

In R, data can be stored in a variety of types. For this tutorial, we will focus on numeric and logical variables.


### Variable types in R

| abbreviation | type | example  |
|---|------|---|
| **numeric** |  |  |
|`int` | integers | `31L`  | 
|`dbl`  | doubles, also known as real numbers | `31.5` |
| **data and time** |  |
|`date` | dates | "2020-10-31" |
|`dttm` | date-times (a date + a time) |
| **other** |  |
|`chr`  | character vectors, also known as strings |
|`fctr` | factors, which R uses to represent categorical variables with fixed possible values |
|`lgl` | logical  | `TRUE`, `FALSE`, `NA` |

**Note:** This is an incomplete list! There are other specialized variable types which you may encouter in later, more advanced settings. These are the types we will be working with in this course.


### Creating numeric variables

Numeric variables are at the centre of most data analysis. In R, numeric variables are stored in two ways: as integers (without decimals), or doubles (from the term "double precision", or [double-precision floating-point](https://en.wikipedia.org/wiki/Double-precision_floating-point_format), a computer number format). 

Doubles get used when you need a number with a decimal point or a number bigger than roughly two billion. [^Mersenne_footnote] 


The downside to doubles is that they are imprecise.

```{r}
# calculate the square root of two, to the 2nd power
x <- sqrt(2) ^ 2
x

# what is x - 2?
x - 2
```

Which isn't precise, but for most application is close enough!

When you are creating a number vector in R, the default state is a double:

```{r}
d <- 1
typeof(d)

# in a data table we see the variable type shown under the variable name
x <- tribble(~x, 1)
x

```



### Logical variables


`lgl` stands for logical, vectors that contain only TRUE, FALSE, or NA.

Some functions Logical values usually appear whe


### Missing values

`NA` are explicitly missing values.

* they can be included as any type: e.g. numeric or character




## 2. Missing Values


### a short example

`is.na` and `anyNA(x)` functions are logical


### Your Turn 1.1: Find the `NA` values

`is.na` and `anyNA(x)` functions are logical

What does `is.na(x)` return? 


```{r missing1, exercise=TRUE, exercise.eval=FALSE}
x <- c(1, NA, 3)

# answer
is.na(x)

```


There are three values in `x`, so three tests--only the second one is `NA`.

What about `anyNA(x)`?

```{r missing2, exercise=TRUE, exercise.eval=FALSE}
# example
x <- c(1, NA, 3)

```



```{r missing2-solution}
x <- c(1, NA, 3)

# answer
anyNA(x)

# There are three values in `x`, so three tests--only the second one is `NA`

```




What if we put an exclamation mark -- the "not" symbol -- in front of `is.na()`? How does it differ from `is.na()`?

```{r missing3, exercise=TRUE, exercise.eval=FALSE}
# example
x <- c(1, NA, 3)

```



```{r missing3-solution}
# example
x <- c(1, NA, 3)

!is.na(x)
```


## Calculating with `NA`


Run this code to see what happens when there are `NA` values in a variable, and you try to sum them.

Use `na.rm` within the `sum()` function to calculate the sum of `x`.


```{r missing4, exercise=TRUE, exercise.eval=FALSE}
# example
x <- c(1, NA, 3)

# example
sum(x)

```



```{r missing4-solution}

# answer
x <- c(1, NA, 3)
sum(x, na.rm = TRUE)


```



### Your Turn 1.2: 

First step: review the structure of the `mpg` data set:

```{r missing1_2_1, exercise=TRUE, exercise.eval=FALSE}
mpg
```


Run to create the `displ_class_by_cyl` table:

* group the cars by class and cylinder size, and 

* show the mean displacement (engine size)

```{r missing1_2_2, exercise=TRUE, exercise.eval=FALSE}
# summary table - class by cylinder
displ_class_by_cyl <- mpg %>%
  group_by(class, cyl) %>%
  summarise(displ_mean = mean(displ)) %>%
  arrange(desc(displ_mean)) %>%
  pivot_wider(names_from = cyl, values_from = displ_mean) %>%
  pivot_longer(-class, names_to = "cyl", values_to = "displ_mean")

displ_class_by_cyl

#saveRDS(displ_class_by_cyl, file = "tutorials/BIDA302_solutions/hands-on_2/displ_class_by_cyl.rds")

```

```{r, include=FALSE}
#load displ_class_by_cyl table (since the output of one chunk doesn't carry forward)

displ_class_by_cyl <- readRDS(file = "displ_class_by_cyl.rds")


```


Calculate the mean of `displ_mean` -- note that there are `NA` values.

```{r missing1_2_3, exercise=TRUE, exercise.eval=FALSE}
# example
mean(displ_class_by_cyl$displ_mean)


```



```{r missing1_2_3-solution}


# solution
mean(displ_class_by_cyl$displ_mean, na.rm = TRUE)

```


An alternative solution: use a filter with `!na` to remove the records with `NA` values:

```{r missing1_2_4, exercise=TRUE, exercise.eval=FALSE}
# example
displ_class_by_cyl %>%
  summarise(displ_mean_all = mean(displ_mean))
```



```{r missing1_2_4-solution}


# solution
displ_class_by_cyl %>%
  filter(!is.na(displ_mean)) %>%
  summarise(displ_mean_all = mean(displ_mean))

```



## Summarize with `group()` and `ungroup()`


You'll notice in #1.2 that when we summarize `displ_class_by_cyl` it gives the mean values by class, even though we didn't use any grouping variable.

This is because when we ran the code to create the `displ_class_by_cyl` table, we grouped by `class` and `cyl`. Running the `summarise()` function is applied, it removes one level of the grouping (in this case, `cyl`): 

```{r missing1_2_5, exercise=TRUE, exercise.eval=FALSE}

# example
displ_class_by_cyl

displ_class_by_cyl %>%
  filter(!is.na(displ_mean)) %>%
  summarise(displ_mean_all = mean(displ_mean))


```


If you want the mean of all the values, you have to use `ungroup()` before `summarise()`, to "peel off" `class`


```{r missing1_2_6, exercise=TRUE, exercise.eval=FALSE}

# solution
displ_class_by_cyl %>%
  filter(!is.na(displ_mean)) %>%
  ungroup() %>%
  summarise(displ_mean_all = mean(displ_mean))


```


## Take aways

* using functions to identify unknown values (`NA`) in a variable
* finding `NA` values
* removing or avoiding `NA` values in calculations




# 2. Import data


<!--

Can't read a csv file locally!

https://github.com/harris-coding-lab/codinglab/issues/3

-->

## 1. Reading a CSV file

CSV files are very commonly used for storing flat files. They don't have any formatting--just the number or text in the cell.

The package {readr} is designed to make importing these files simple.


(This example comes straight from https://readr.tidyverse.org/index.html)

Run this chunk to create an object called `mtcars`, from a CSV file of the same name.

```{r import2_1_1, exercise=TRUE, exercise.eval=FALSE}

# example
mtcars <- read_csv("mtcars.csv")

```

Adding the `cols()` allows us to alter what {readr} has decided for us. For example, we could set the `cyl` variable to be an integer.

```{r import2_1_2, exercise=TRUE, , exercise.eval=FALSE}
# example
read_csv("mtcars.csv",
         col_types =
           cols(cyl = col_integer())
         )

```


## Your Turn 1.1

Insert an R chunk and rerun the example above, but with the `am` and `gear` variables also set to integer.

```{r import2_1_3, exercise=TRUE, , exercise.eval=FALSE}

```


```{r import2_1_3-solution}
# solution
read_csv("mtcars.csv",
         col_types = 
           cols(cyl = col_integer(),
                am = col_integer(),
                gear = col_integer())
)

```




The {readr} package allows a lot of control over how the file is read. Of particular utility are 

* `na = ""` -- specify which values you want to be turned into `NA`

* `skip = 0` -- specify how many rows to skip 

* `n_max = Inf` -- the maximum number of records to read


## Your Turn 1.2

Read the first 5 rows of the "mtcars.csv" file.

```{r import2_1_4, exercise=TRUE, , exercise.eval=FALSE}

```


```{r import2_1_4-solution}
# solution
read_csv("mtcars.csv", 
         n_max = 5)



```






## 2. Reading an Excel file

If anything, Excel files are more common than CSV and other plain-text data files. They seem to multiply like coat hangers in the closet...

And as we see in the article by Karl Broman & Kara Woo, ["Data Organization in Spreadsheets"](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989), they can encourage some ways of storing information that makes it hard for us to analyze. Excel files can also contain a wide variety of data format types. {readxl} tries to figure out what's going on, but like {readr}, it allows you to override some of those automatic decisions.


```{r import2_2_1, exercise=TRUE, , exercise.eval=FALSE}
deaths <- read_excel("data/deaths.xlsx")
deaths
```

What do you notice about the "Date of birth" and "Date of death" columns?



```{r quiz_import_1}
quiz(
  question("What do you notice about the `Date of birth` and `Date of death` columns?",
    answer("It's exactly the same as it was before"),
    answer("The variables (columns) are in different order"),
    answer("There are now `NA` values", correct = TRUE),
    answer("The values in the cells have changed")
  )
)
```



## Your Turn 2.1

Read in the "deaths" file, but use the `range = ` option to specify when to start reading the file:

In this first example, we will define the range as cells A1:B3

```{r import2_2_2, exercise=TRUE, , exercise.eval=FALSE}
# Example
deaths <- read_excel("deaths.xlsx", 
                     range = "A1:B3")

deaths

```

But we want a bigger area...but drop the first few rows.

```{r import2_2_3, exercise=TRUE, , exercise.eval=FALSE}

```

```{r import2_2_3-solution}
# solution
deaths <- read_excel(
  "deaths.xlsx",
  range = "A5:F15"
)

deaths

```


Use the `skip =` and `n_max =` options to achieve the same thing:

```{r}

# solution
deaths <- read_excel(
  readxl_example("deaths.xlsx"),
  skip = 4,
  n_max = 10
)

deaths


```


## Your Turn 2.2

Excel files often (almost always?) have multiple sheets in them. It's possible to specify which one you want to use with the `sheets = ""` option. You can also use the position number (if you happen to know it). 

Note that if you don't specify the sheet, {readxl} will default to the first one.

The `excel_sheets()` function will tell you the name of the sheets in an Excel file.

```{r}
datasets <- "datasets.xlsx"

excel_sheets(datasets)

# Example
read_excel(datasets, "iris")

```

Now, read in the "mtcars" sheet using the name of the sheet.


```{r}

# Solution
read_excel(datasets, "mtcars")

```

And finally, read in the "quakes" sheet, using the position.

```{r}
# Solution
read_excel(datasets, 4)

```




## Import data - reference material

You can find more details in _R for Data Science_:
https://r4ds.had.co.nz/data-import.html


{readr} 
https://readr.tidyverse.org/

{readxl}
https://readxl.tidyverse.org/index.html

***

https://stackoverflow.com/questions/63675677/include-a-chunk-in-an-r-markdown-footnote

[^Mersenne_footnote]:

The maximum positive value for a 32-bit binary integer is 2,147,483,647. This number is tied to the how numbers are stored in 32-bit computers, and is represented as (2^31 - 1). For you number nerds, this happens to be a [double Mersenne prime number](https://en.wikipedia.org/wiki/Double_Mersenne_number).

```{r}
# a Mersenne prime is a prime number that can be represented as "2^n - 1"
2^31-1

# a double Mersenne prime a Mersenne prime is where "n" is also a Mersenne prime
# - in this case, 31 is a Mersenne prime (it's a prime number, and is 2^5 - 1)
2^(2^5-1)-1 

```



